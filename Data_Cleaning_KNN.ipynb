{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6287a63",
   "metadata": {},
   "source": [
    "## Library Import\n",
    "NumPy, pandas, matplotlib, seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1356006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4a1b4",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e115c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d34cb",
   "metadata": {},
   "source": [
    "Todo things:    \n",
    "Missing data  \n",
    "Outliers  \n",
    "TimeSeries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "147913af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type :  <class 'pandas.core.frame.DataFrame'>\n",
      "Data dims :  (145460, 23)\n",
      "Date              object\n",
      "Location          object\n",
      "MinTemp          float64\n",
      "MaxTemp          float64\n",
      "Rainfall         float64\n",
      "Evaporation      float64\n",
      "Sunshine         float64\n",
      "WindGustDir       object\n",
      "WindGustSpeed    float64\n",
      "WindDir9am        object\n",
      "WindDir3pm        object\n",
      "WindSpeed9am     float64\n",
      "WindSpeed3pm     float64\n",
      "Humidity9am      float64\n",
      "Humidity3pm      float64\n",
      "Pressure9am      float64\n",
      "Pressure3pm      float64\n",
      "Cloud9am         float64\n",
      "Cloud3pm         float64\n",
      "Temp9am          float64\n",
      "Temp3pm          float64\n",
      "RainToday         object\n",
      "RainTomorrow      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type : \", type(data))\n",
    "print(\"Data dims : \", data.shape)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff91aee",
   "metadata": {},
   "source": [
    "## Cleaning the dataset\n",
    "\n",
    "* Removing duplicate\n",
    "* Handling missing values\n",
    "* Detect and handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ede784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dims :  (145460, 23)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates\n",
    "data.drop_duplicates()\n",
    "# After removing\n",
    "print(\"Data dims : \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef09594",
   "metadata": {},
   "source": [
    "No duplicates were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cfe79",
   "metadata": {},
   "source": [
    "The extend of missing data is severe, thus imputation is applied to preserve data. Since the data is TimeSeries, we are using interpolation for severely missing variables. Missing values from RainTomorrow is dropped. For variables with less missing values we use median and mode imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dda5336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned[columns_large_missing] = data_cleaned[columns_large_missing].interpolate(method='time')\n",
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned[columns_few_missing_num] = data_cleaned[columns_few_missing_num].apply(lambda x: x.fillna(x.median()))\n",
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned[columns_few_missing_cat] = data_cleaned[columns_few_missing_cat].apply(lambda x: x.fillna(x.mode()[0]))\n",
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Evaporation'] = data_cleaned['Evaporation'].fillna(data_cleaned['Evaporation'].median())\n",
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Sunshine'] = data_cleaned['Sunshine'].fillna(data_cleaned['Sunshine'].median())\n",
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_87274/4218231755.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Cloud3pm'] = data_cleaned['Cloud3pm'].fillna(data_cleaned['Cloud3pm'].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# Define columns for imputation strategies\n",
    "columns_large_missing = ['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm']\n",
    "columns_few_missing_num = ['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', \n",
    "                           'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', \n",
    "                           'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "columns_few_missing_cat = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
    "\n",
    "# Remove rows where 'RainTomorrow' is missing\n",
    "data_cleaned = data.dropna(subset=['RainTomorrow'])\n",
    "\n",
    "# Convert 'Date' to datetime and set as index for interpolation\n",
    "data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
    "data_cleaned.set_index('Date', inplace=True)\n",
    "\n",
    "# Apply interpolation for columns with large amounts of missing data\n",
    "data_cleaned[columns_large_missing] = data_cleaned[columns_large_missing].interpolate(method='time')\n",
    "\n",
    "# Reset index\n",
    "data_cleaned.reset_index(inplace=True)\n",
    "\n",
    "# Impute missing values for columns with fewer missing values\n",
    "# Numerical columns: Using median\n",
    "data_cleaned[columns_few_missing_num] = data_cleaned[columns_few_missing_num].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Categorical columns: Using mode\n",
    "data_cleaned[columns_few_missing_cat] = data_cleaned[columns_few_missing_cat].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Final imputation for the few remaining missing values in 'Evaporation', 'Sunshine', and 'Cloud3pm'\n",
    "data_cleaned['Evaporation'] = data_cleaned['Evaporation'].fillna(data_cleaned['Evaporation'].median())\n",
    "data_cleaned['Sunshine'] = data_cleaned['Sunshine'].fillna(data_cleaned['Sunshine'].median())\n",
    "data_cleaned['Cloud3pm'] = data_cleaned['Cloud3pm'].fillna(data_cleaned['Cloud3pm'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784e523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/77/zprx85k56yb71r3z1m9phb3w0000gn/T/ipykernel_1339/885836893.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rain_categorical[col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming 'rain' is your DataFrame\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = rain.select_dtypes(include=['float64']).columns.difference(['Cloud9am', 'Cloud3pm'])\n",
    "categorical_cols = rain.select_dtypes(include=['object']).columns.tolist() + ['Cloud9am', 'Cloud3pm']\n",
    "\n",
    "# Separate the DataFrame into numerical and categorical DataFrames\n",
    "rain_numerical = rain[numerical_cols]\n",
    "rain_categorical = rain[categorical_cols]\n",
    "\n",
    "# Apply KNN Imputation to numerical data\n",
    "# It's a good practice to scale numerical data before applying KNN imputation\n",
    "scaler = MinMaxScaler()\n",
    "rain_numerical_scaled = scaler.fit_transform(rain_numerical)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "rain_numerical_imputed_scaled = knn_imputer.fit_transform(rain_numerical_scaled)\n",
    "# Inverse transform to original scale after imputation\n",
    "rain_numerical_imputed = scaler.inverse_transform(rain_numerical_imputed_scaled)\n",
    "rain_numerical_imputed = pd.DataFrame(rain_numerical_imputed, columns=numerical_cols, index=rain_numerical.index)\n",
    "\n",
    "# Apply Mode Imputation to categorical data\n",
    "for col in categorical_cols:\n",
    "    mode_value = rain_categorical[col].mode()[0]\n",
    "    rain_categorical[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Merge the imputed numerical and categorical data back into a single DataFrame\n",
    "rain_imputed = pd.concat([rain_numerical_imputed, rain_categorical], axis=1)\n",
    "\n",
    "# Ensuring the original column order is preserved\n",
    "rain_imputed = rain_imputed[rain.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8191990",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5489a30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dims :  (145460, 23)\n",
      "Date              object\n",
      "Location          object\n",
      "MinTemp          float64\n",
      "MaxTemp          float64\n",
      "Rainfall         float64\n",
      "Evaporation      float64\n",
      "Sunshine         float64\n",
      "WindGustDir       object\n",
      "WindGustSpeed    float64\n",
      "WindDir9am        object\n",
      "WindDir3pm        object\n",
      "WindSpeed9am     float64\n",
      "WindSpeed3pm     float64\n",
      "Humidity9am      float64\n",
      "Humidity3pm      float64\n",
      "Pressure9am      float64\n",
      "Pressure3pm      float64\n",
      "Cloud9am         float64\n",
      "Cloud3pm         float64\n",
      "Temp9am          float64\n",
      "Temp3pm          float64\n",
      "RainToday         object\n",
      "RainTomorrow      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.head()\n",
    "print(\"Data dims : \", data.shape)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff706b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data \n",
    "rain_encoded.to_csv('data/weatherAUS_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38326d",
   "metadata": {},
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068dc62",
   "metadata": {},
   "source": [
    "## More EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ffc27",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de769c",
   "metadata": {},
   "source": [
    "## Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9173cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
